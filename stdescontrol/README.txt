# An Optimization Approach for Supervised Control of Stochastic Timed Discrete Event Systems based on Reinforcement Learning

This package contains implementations of SCT-Timed RL algorithm for STDES system simulated with automata & gym. This paper proposes an optimization approach for 
supervised control of stochastic timed discrete event systems (STDES) integrating reinforcement learning (RL) with supervisory control theory (SCT). Different from 
crisp discrete event systems (CDES) with disregarding the time, STDES analyzes more complex dynamic systems which consider of general distributions for sojourn times 
between states. In this work, the language of the uncontrolled system and its deterministic specification are firstly generated by automata according to the logic 
features of STDES system; Then, a supervisor is derived using SCT to ensure system safety by disabling specific controllable event sequences; Next, the controlled 
automata structure from SCT is converted into a SMDP framework by adding the temporal and probabilistic variable of the uncontrollable events. Finally, a modified 
SCT-Timed RL adaptive control algorithm is developed to optimize system performance by designing a new Bellman equation and reward function. The results show that 
the proposed controller enhances system safety and flexibility, with an 8.9% performance improvement over non-intelligent method.

# Installation
The main package dependencies are `Gym`, `python=3.8`, `gym>=0.13`, SUPREMICA software for SCT. See `setup/README.md` for detailed install instructions.

# Getting started
Each repository above contains detailed setup instructions. 
1. **Step 1:** Install [gym], using instructions in the repository. `gym` comes with an anaconda environment which helps to easily import and use a variety of gym tasks.
2. **Step 2:** Install [envs] by following the instructions in the repository. Note that `automataEnv
` uses git submodules, and hence must be cloned correctly per instructions in the repo.
3. **Step 3:** “Stdes.xml” is the XML generated by the SUPREMICA software. The content is the state machine structure from SCT.
4. **Step 4:** “Sct_RL.py”, run this for proposed SCT-Timed RL method for the optimal control algorithm based on SCT & reinforcement learning.

#  Workspace description
The manufacturing system is defined as a set of sub-automata $M_{i}=(Q_{i}, \Sigma_{i}, f_{i}, \Gamma _{i}, q_{i0}, Q_{im})$, which is shown in Fig. \ref{fig3} with the 
software "Supremica", where MI and MS represent the machines featuring two states that transition through start and finish actions. MO, MP, and MR are designed as machines
that operate on two different types of vehicles. MQ expresses both types can either leave or be reworked. The composition $G=MI \parallel MR \parallel Ms \parallel Mo \parallel Mp \parallel MQ$ 
creates 540 unrestricted states of the system. 	

![Example Image](1.jpg)